{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "Colorization_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnikhilK/ML_Learn/blob/main/Colorization_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "396ca69a"
      },
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "id": "396ca69a",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54c43b9c"
      },
      "source": [
        ""
      ],
      "id": "54c43b9c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db9a1ba4"
      },
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
        "tf.keras.backend.compat.v1.set_session(tf.Session(config=config));"
      ],
      "id": "db9a1ba4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae42fdd0",
        "outputId": "b5acc120-0df3-4070-b0e5-d7219a9fe7b2"
      },
      "source": [
        "tf.config.list_physical_devices('GPU') "
      ],
      "id": "ae42fdd0",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "837f9410"
      },
      "source": [
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
      ],
      "id": "837f9410",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_FMAaoM9SBF",
        "outputId": "8a4e6355-1656-4e0f-f5df-32991e57279c"
      },
      "source": [
        "os.listdir"
      ],
      "id": "b_FMAaoM9SBF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function posix.listdir>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b6sMletN9VFM",
        "outputId": "85fa2f72-7e5a-4605-b332-b75f3bafdee1"
      },
      "source": [
        "os.getcwd()"
      ],
      "id": "b6sMletN9VFM",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb03c67e"
      },
      "source": [
        "# Get images\n",
        "X = []\n",
        "for filename in os.listdir('/content/Train'):\n",
        "    X.append(img_to_array(load_img('/content/Train/'+filename)))\n",
        "X = np.array(X, dtype=float)\n",
        "\n",
        "# Set up train and test data\n",
        "split = int(0.95*len(X))\n",
        "Xtrain = X[:split]\n",
        "Xtrain = 1.0/255*Xtrain"
      ],
      "id": "eb03c67e",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "271425ad"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.compile(optimizer='rmsprop', loss='mse')"
      ],
      "id": "271425ad",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f30bef6b"
      },
      "source": [
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# Generate training data\n",
        "batch_size = 100000\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"
      ],
      "id": "f30bef6b",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5581e7b8"
      },
      "source": [
        "# Train model      \n",
        "tensorboard = TensorBoard(log_dir=\"output/first_run\")"
      ],
      "id": "5581e7b8",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acf7b5a4",
        "outputId": "2463d898-17c9-4fef-ccf3-1ca46b68e9e9"
      },
      "source": [
        "model.fit(image_a_b_gen(batch_size), epochs=10, steps_per_epoch=250)"
      ],
      "id": "acf7b5a4",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 139s 557ms/step - loss: 0.0082\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 139s 555ms/step - loss: 0.0056\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 138s 552ms/step - loss: 0.0038\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 137s 548ms/step - loss: 0.0028\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 137s 547ms/step - loss: 0.0024\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 137s 547ms/step - loss: 0.0020\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 137s 549ms/step - loss: 0.0015\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 137s 548ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 137s 547ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 137s 546ms/step - loss: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5067176a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c6bfe01"
      },
      "source": [
        "# Save model\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")"
      ],
      "id": "3c6bfe01",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ac6f06",
        "outputId": "1c88c1c1-e601-4d04-82f4-7f9c98a72552"
      },
      "source": [
        "# Test images\n",
        "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
        "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
        "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
        "Ytest = Ytest / 128\n",
        "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
      ],
      "id": "f4ac6f06",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0036\n",
            "0.0035598445683717728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72e08617"
      },
      "source": [
        "color_me = []\n",
        "for filename in os.listdir('/content/Test/'):\n",
        "    color_me.append(img_to_array(load_img('/content/Test/'+filename)))\n",
        "color_me = np.array(color_me, dtype=float)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "# Test model\n",
        "output = model.predict(color_me)\n",
        "output = output * 128"
      ],
      "id": "72e08617",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d9d2b12",
        "outputId": "ae2b0827-ba92-419a-e5d3-2cabce3a0029"
      },
      "source": [
        "# Output colorizations\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    imsave(\"Res/img_\"+str(i)+\".png\", lab2rgb(cur))"
      ],
      "id": "4d9d2b12",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}